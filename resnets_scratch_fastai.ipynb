{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnets_scratch_fastai.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPt51FzfSyiRtqb6Z6kqG6q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Davilirio/Neural-Nets/blob/master/resnets_scratch_fastai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QnFwgq6rlrL",
        "colab_type": "text"
      },
      "source": [
        "Writing resnets and densenets in pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g1dxKpFVNd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKOnw9CwfBtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.MNIST)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjNOtnDHfVGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC0-T99sfWRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating imagelist from the path above,\n",
        "# converting data into PIL L (grayscale) images.\n",
        "il = ImageList.from_folder(path, convert_mode='L')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlVkHDFgf79O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# matplotlib reverse binary color map\n",
        "# (I was researching colormaps documentation)\n",
        "defaults.cmap='binary_r'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt3HSyRkfzOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "il[0].show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYKArM1mgr8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# in fastai v1 you have to explicitly say where are the data for validation\n",
        "sd = il.split_by_folder(train='training',valid='testing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnikzmcTf3Jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lbl_list = sd.label_from_folder()\n",
        "lbl_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR4YiT2ZgpBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we can enter the datablock api and see each item inside\n",
        "x, y = lbl_list.train[0]\n",
        "y, x.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8tgL8LDhEhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# writing transforms:\n",
        "# since the data is all black, we use zero in padding as its 1 channel and black\n",
        "# size of the data will be 28, and the second list is for valid tfms, NONE\n",
        "# * means get both things rand_pad returns\n",
        "\n",
        "tfms = ([*rand_pad(padding=3, size=28, mode='zeros')],[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G48-6NeGhaYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining the batch size for our problem\n",
        "bs = 128\n",
        "\n",
        "# applying the transforms, creating databunch and normalizing data \n",
        "data = (lbl_list.transform(tfms)\n",
        "                .databunch(bs=bs)\n",
        "                .normalize())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faBgD5c-hbGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we can enter any dataset:\n",
        "x, y = data.train_ds[0]\n",
        "y, x.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9vGSqupivUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.show_batch(rows=4, figsize=(6, 6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGYzToe2klJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBbyTMfSjLS6",
        "colab_type": "text"
      },
      "source": [
        "### Basic CNN with batch normzalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "862Lvt3xjYVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ni = number of inputs\n",
        "# nf = number of features\n",
        "def conv(ni, nf): return nn.Conv2d(ni, nf, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    conv(1, 8), # size=14\n",
        "    nn.BatchNorm2d(8),\n",
        "    nn.ReLU(),\n",
        "    conv(8, 16), # size=7\n",
        "    nn.BatchNorm2d(16),\n",
        "    nn.ReLU(),\n",
        "    conv(16, 32), # size=4\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.ReLU(),\n",
        "    conv(32, 16), # size=2\n",
        "    nn.BatchNorm2d(16),\n",
        "    nn.ReLU(),\n",
        "    conv(16, 10), # size= 1\n",
        "    nn.BatchNorm2d(10),\n",
        "    Flatten() # vectorizes the (10, 1, 1) rank 3 tensor to create the pred\n",
        ") \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b6c-pHPkvoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining a fastai learner with this model\n",
        "\n",
        "learner = Learner(data, model, loss_func=nn.CrossEntropyLoss(), metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLOu2PLrnO0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIFu98DqnsSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.recorder.plot(end_lr=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7GBBy8Qnu86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit_one_cycle(3,max_lr=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRZLLa8Zn_K0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit_one_cycle()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwkQcWutlEzO",
        "colab_type": "text"
      },
      "source": [
        "#### Refactoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmpgzNxYlT0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# conv_layer() creates a conv2d, reLU, BN sequence\n",
        "\n",
        "def conv2(ni, nf): return conv_layer(ni, nf, stride=2)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    conv2(1, 8), # size=14\n",
        "    conv2(8, 16), # size=7\n",
        "    conv2(16,32), # size=4\n",
        "    conv2(32, 16), # size=2\n",
        "    conv2(16, 10), # size=1\n",
        "    Flatten()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmw9I0aAmeVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner = Learner(data, model, loss_func=nn.CrossEntropyLoss(), metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytQKWJsuoDWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfmo8acSpn3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit_one_cycle(6,max_lr=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XceBp7Rxp1_R",
        "colab_type": "text"
      },
      "source": [
        "### Kind of ResNet-ish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNwJToe3ra4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating a module that contains residue at the end\n",
        "class ResBlock(nn.Module):\n",
        "  # defining the self atributtes of the block\n",
        "  def __init__(self, nf):\n",
        "    # super init to overwrite our own module\n",
        "    super(ResBlock, self).__init__()\n",
        "    # defining our conv_layers that take number of features as inputs\n",
        "    self.conv1 = conv_layer(nf, nf)\n",
        "    self.conv2 = conv_layer(nf, nf)\n",
        "  \n",
        "  # foward takes the attributes and the input\n",
        "  def forward(self, input):\n",
        "    # returns the input (residue) and the activations from passing 2 conv_layers\n",
        "    return input + self.conv2(self.conv1(input))\n",
        "\n",
        "# create a simple function just for testing\n",
        "def resblck(nf): return ResBlock(nf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH4BobuNGgq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating a model using the residual learning resblock\n",
        "# just paste the model above and add resblocks between layers\n",
        "\n",
        "model = nn.Sequential(\n",
        "    conv2(1, 8), # size=14\n",
        "    resblck(8),\n",
        "    conv2(8, 16), # size=7\n",
        "    resblck(16),\n",
        "    conv2(16,32), # size=4\n",
        "    resblck(32),\n",
        "    conv2(32, 16), # size=2\n",
        "    resblck(16),\n",
        "    conv2(16, 10), # size=1\n",
        "    Flatten()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrqbM-OlG8o2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, model, loss_func=nn.CrossEntropyLoss(), metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJFkROCKIg-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXZ5IXsgIiVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(12, max_lr=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuyYswiPJBGX",
        "colab_type": "text"
      },
      "source": [
        "#### Refactoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC2sYnQ-LU1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_conv(ni, nf): return nn.Sequential(conv2(ni, nf), resblck(nf))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOxKm5UvLkPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "    res_conv(1,8), # size 14\n",
        "    res_conv(8,16), # size 7\n",
        "    res_conv(16,32), # size 4\n",
        "    res_conv(32,16), # size 2\n",
        "    res_conv(16,data.c), # size 1\n",
        "    Flatten() # vectorizes the (10,1,1) rank 3 tensor\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeZEp8p6MBZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, model, loss_func=nn.CrossEntropyLoss(), metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNOAzWmhMIsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxA_tLikMKSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvpdB5g4MNqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(12, max_lr=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzFBNsgSQPjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# writing in fastai module sequential extended\n",
        "model_fst = SequentialEx(res_conv(1,8),\n",
        "                         res_conv(8,16),\n",
        "                         res_conv(16, 32),\n",
        "                         res_conv(32, 16),\n",
        "                         res_conv(16, 10),\n",
        "                         Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPbM2u2gTdSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb, yb = data.one_batch()\n",
        "xb.shape, yb.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g1C59nmThma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# outputs in expected size, so modelling was correct\n",
        "model_fst(xb).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irvCl2hyMYqH",
        "colab_type": "text"
      },
      "source": [
        "### DenseNet-ish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ1UG6oSM6KE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a densenet differs from a resnet mostly in the way the skip connection\n",
        "# interacts with the activations. Instead of being in sum format, it is \n",
        "# in concat format.\n",
        "\n",
        "# creating a module that contains residue at the end (concatenated)\n",
        "class DenseBlock(nn.Module):\n",
        "  # defining the self atributtes of the block\n",
        "  def __init__(self, nf):\n",
        "    # super init to overwrite our own module\n",
        "    super(DenseBlock, self).__init__()\n",
        "    # defining our conv_layers that take number of features as inputs\n",
        "    self.conv1 = conv_layer(nf, nf)\n",
        "    self.conv2 = conv_layer(nf, nf)\n",
        "  \n",
        "  # foward takes the attributes and the input\n",
        "  def forward(self, input):\n",
        "    activations = self.conv2(self.conv1(input))\n",
        "    # returns the input (residue) and the activations from passing 2 conv_layers\n",
        "    return torch.cat((activations, input), dim=1)\n",
        "\n",
        "## OBS: AS THE OUTPUTS OF A CONV LAYER DIFFER, THE SIZES OF INPUTS TO THE NEXT\n",
        "## LAYER MUST BE CHANGED"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n3tb-rkTlQr",
        "colab_type": "text"
      },
      "source": [
        "#### DenseNet in Sequential Extended\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH6MmvR-UJ9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating func that has torch.cat in the merging process\n",
        "def denselayer(ni, nf): return nn.Sequential(conv_layer(ni, nf),\n",
        "                                             conv_layer(nf, nf),\n",
        "                                             conv_layer(nf, nf),\n",
        "                                             MergeLayer(dense=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyqAG3FOUFRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## creating model with the simplified func above\n",
        "## errors to be corrected here!\n",
        "model = SequentialEx(\n",
        "    denselayer(1, 8), # sz 14\n",
        "    denselayer(8, 16), # sz 7\n",
        "    denselayer(16, 32), # sz 4\n",
        "    denselayer(32, 16), # sz 2\n",
        "    denselayer(16, 10), # sz 1\n",
        "    Flatten()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-kgI19-VXst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}